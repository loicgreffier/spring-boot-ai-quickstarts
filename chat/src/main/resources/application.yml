spring:
  ai:
    model:
      embedding: "none"
    ollama:
      base-url: "http://localhost:11434"
      chat:
        options:
          model: "gemma3:4b"
          temperature: 0.8
      init:
        pull-model-strategy: "ALWAYS"
        timeout: "10m"
